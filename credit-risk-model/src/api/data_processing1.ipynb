{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "35336c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f0a520c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "566c7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()\n",
    "df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])\n",
    "# Create new columns\n",
    "df['Transaction Hour'] = df['TransactionStartTime'].dt.hour\n",
    "df['Transaction Day'] = df['TransactionStartTime'].dt.day\n",
    "df['Transaction Month'] = df['TransactionStartTime'].dt.month\n",
    "df['Transaction Year'] = df['TransactionStartTime'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b2fedd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CountryCode'] = df['CountryCode'].astype(str)  # Ensure CountryCode is treated as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1e8ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
       "       'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
       "       'ProductCategory', 'ChannelId'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df = df.select_dtypes(include=['object', 'category'])\n",
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e57109cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Amount', 'Value', 'PricingStrategy', 'FraudResult', 'Transaction Hour',\n",
       "       'Transaction Day', 'Transaction Month', 'Transaction Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = df.select_dtypes(include=['number'])\n",
    "numerical_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e1bcf4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns for numerical and categorical features\n",
    "numerical_features = ['Amount', 'Value', 'PricingStrategy', 'FraudResult', 'Transaction Hour','Transaction Day', 'Transaction Month', 'Transaction Year']\n",
    "categorical_features = ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId','CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId','ProductCategory', 'ChannelId']\n",
    "\n",
    "# Create the preprocessing pipeline for numerical features\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Impute missing values with mean\n",
    "    ('scaler', MinMaxScaler())                    # Normalize\n",
    "])\n",
    "\n",
    "# Create the preprocessing pipeline for categorical features\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))  # Impute missing values with mode\n",
    "])\n",
    "\n",
    "# Combine both pipelines into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "df_transformed = preprocessor.fit_transform(df)\n",
    "\n",
    "# Convert the transformed data back to a DataFrame\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=numerical_features + categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "03f091ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Value</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "      <th>Transaction Hour</th>\n",
       "      <th>Transaction Day</th>\n",
       "      <th>Transaction Month</th>\n",
       "      <th>Transaction Year</th>\n",
       "      <th>TransactionId</th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CurrencyCode</th>\n",
       "      <th>CountryCode</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092004</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TransactionId_76871</td>\n",
       "      <td>BatchId_36123</td>\n",
       "      <td>AccountId_3957</td>\n",
       "      <td>SubscriptionId_887</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.09191</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TransactionId_73770</td>\n",
       "      <td>BatchId_15642</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_4406</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.091958</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TransactionId_26203</td>\n",
       "      <td>BatchId_53941</td>\n",
       "      <td>AccountId_4229</td>\n",
       "      <td>SubscriptionId_222</td>\n",
       "      <td>CustomerId_4683</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_1</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TransactionId_380</td>\n",
       "      <td>BatchId_102363</td>\n",
       "      <td>AccountId_648</td>\n",
       "      <td>SubscriptionId_2185</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_21</td>\n",
       "      <td>utility_bill</td>\n",
       "      <td>ChannelId_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091853</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TransactionId_28195</td>\n",
       "      <td>BatchId_38780</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_988</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95657</th>\n",
       "      <td>0.09182</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TransactionId_89881</td>\n",
       "      <td>BatchId_96668</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_3078</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95658</th>\n",
       "      <td>0.092004</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TransactionId_91597</td>\n",
       "      <td>BatchId_3503</td>\n",
       "      <td>AccountId_3439</td>\n",
       "      <td>SubscriptionId_2643</td>\n",
       "      <td>CustomerId_3874</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_10</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95659</th>\n",
       "      <td>0.09191</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TransactionId_82501</td>\n",
       "      <td>BatchId_118602</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_3874</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95660</th>\n",
       "      <td>0.092188</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TransactionId_136354</td>\n",
       "      <td>BatchId_70924</td>\n",
       "      <td>AccountId_1346</td>\n",
       "      <td>SubscriptionId_652</td>\n",
       "      <td>CustomerId_1709</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_19</td>\n",
       "      <td>tv</td>\n",
       "      <td>ChannelId_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95661</th>\n",
       "      <td>0.091906</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TransactionId_35670</td>\n",
       "      <td>BatchId_29317</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_1709</td>\n",
       "      <td>UGX</td>\n",
       "      <td>256</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95662 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Amount     Value PricingStrategy FraudResult Transaction Hour  \\\n",
       "0      0.092004  0.000101             0.5         0.0         0.086957   \n",
       "1       0.09191  0.000002             0.5         0.0         0.086957   \n",
       "2      0.091958   0.00005             0.5         0.0         0.086957   \n",
       "3       0.09375  0.002206             0.5         0.0         0.130435   \n",
       "4      0.091853  0.000065             0.5         0.0         0.130435   \n",
       "...         ...       ...             ...         ...              ...   \n",
       "95657   0.09182  0.000101             0.5         0.0         0.391304   \n",
       "95658  0.092004  0.000101             0.5         0.0         0.391304   \n",
       "95659   0.09191  0.000002             0.5         0.0         0.391304   \n",
       "95660  0.092188  0.000303             0.5         0.0         0.434783   \n",
       "95661  0.091906  0.000006             0.5         0.0         0.434783   \n",
       "\n",
       "      Transaction Day Transaction Month Transaction Year  \\\n",
       "0            0.466667          0.909091              0.0   \n",
       "1            0.466667          0.909091              0.0   \n",
       "2            0.466667          0.909091              0.0   \n",
       "3            0.466667          0.909091              0.0   \n",
       "4            0.466667          0.909091              0.0   \n",
       "...               ...               ...              ...   \n",
       "95657             0.4          0.090909              1.0   \n",
       "95658             0.4          0.090909              1.0   \n",
       "95659             0.4          0.090909              1.0   \n",
       "95660             0.4          0.090909              1.0   \n",
       "95661             0.4          0.090909              1.0   \n",
       "\n",
       "              TransactionId         BatchId       AccountId  \\\n",
       "0       TransactionId_76871   BatchId_36123  AccountId_3957   \n",
       "1       TransactionId_73770   BatchId_15642  AccountId_4841   \n",
       "2       TransactionId_26203   BatchId_53941  AccountId_4229   \n",
       "3         TransactionId_380  BatchId_102363   AccountId_648   \n",
       "4       TransactionId_28195   BatchId_38780  AccountId_4841   \n",
       "...                     ...             ...             ...   \n",
       "95657   TransactionId_89881   BatchId_96668  AccountId_4841   \n",
       "95658   TransactionId_91597    BatchId_3503  AccountId_3439   \n",
       "95659   TransactionId_82501  BatchId_118602  AccountId_4841   \n",
       "95660  TransactionId_136354   BatchId_70924  AccountId_1346   \n",
       "95661   TransactionId_35670   BatchId_29317  AccountId_4841   \n",
       "\n",
       "            SubscriptionId       CustomerId CurrencyCode CountryCode  \\\n",
       "0       SubscriptionId_887  CustomerId_4406          UGX         256   \n",
       "1      SubscriptionId_3829  CustomerId_4406          UGX         256   \n",
       "2       SubscriptionId_222  CustomerId_4683          UGX         256   \n",
       "3      SubscriptionId_2185   CustomerId_988          UGX         256   \n",
       "4      SubscriptionId_3829   CustomerId_988          UGX         256   \n",
       "...                    ...              ...          ...         ...   \n",
       "95657  SubscriptionId_3829  CustomerId_3078          UGX         256   \n",
       "95658  SubscriptionId_2643  CustomerId_3874          UGX         256   \n",
       "95659  SubscriptionId_3829  CustomerId_3874          UGX         256   \n",
       "95660   SubscriptionId_652  CustomerId_1709          UGX         256   \n",
       "95661  SubscriptionId_3829  CustomerId_1709          UGX         256   \n",
       "\n",
       "         ProviderId     ProductId     ProductCategory    ChannelId  \n",
       "0      ProviderId_6  ProductId_10             airtime  ChannelId_3  \n",
       "1      ProviderId_4   ProductId_6  financial_services  ChannelId_2  \n",
       "2      ProviderId_6   ProductId_1             airtime  ChannelId_3  \n",
       "3      ProviderId_1  ProductId_21        utility_bill  ChannelId_3  \n",
       "4      ProviderId_4   ProductId_6  financial_services  ChannelId_2  \n",
       "...             ...           ...                 ...          ...  \n",
       "95657  ProviderId_4   ProductId_6  financial_services  ChannelId_2  \n",
       "95658  ProviderId_6  ProductId_10             airtime  ChannelId_3  \n",
       "95659  ProviderId_4   ProductId_6  financial_services  ChannelId_2  \n",
       "95660  ProviderId_6  ProductId_19                  tv  ChannelId_3  \n",
       "95661  ProviderId_4   ProductId_6  financial_services  ChannelId_2  \n",
       "\n",
       "[95662 rows x 19 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c51e8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "# Fit and transform the specified columns\n",
    "columns_to_encode = ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId','CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId','ProductCategory', 'ChannelId']\n",
    "# Apply label encoding to each column individually\n",
    "for column in columns_to_encode:\n",
    "    df_transformed[column] = le.fit_transform(df_transformed[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "224ed55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(min_max_scaler.fit_transform(df_transformed), columns=df_transformed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "50addca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.to_csv('Final_preprocessed_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c9f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sample Transaction Data ---\n",
      "   CustomerId TransactionDate      Amount\n",
      "0           1      2024-03-11  951.207163\n",
      "1           1      2023-04-17  781.894090\n",
      "2           1      2023-01-21  164.458454\n",
      "3           1      2024-04-11  108.975167\n",
      "4           1      2024-04-03  867.514384\n",
      "\n",
      "Total transactions: 7537\n",
      "Unique customers: 500\n",
      "\n",
      "Snapshot Date for Recency calculation: 2024-12-31 00:00:00\n",
      "\n",
      "--- Calculated RFM Metrics (Raw) ---\n",
      "   CustomerId  Recency  Frequency      Monetary\n",
      "0           1      264          7   3055.866058\n",
      "1           2      345          2   1024.124932\n",
      "2           3       84         21   9982.865502\n",
      "3           4        4         26  13820.978961\n",
      "4           5       32         14   7128.400071\n",
      "\n",
      "RFM DataFrame shape: (500, 4)\n",
      "\n",
      "--- Scaled RFM Features ---\n",
      "    Recency  Frequency  Monetary\n",
      "0  1.920143  -0.982761 -1.058853\n",
      "1  2.724721  -1.591358 -1.533300\n",
      "2  0.132189   0.721308  0.558724\n",
      "3 -0.662457   1.329905  1.454991\n",
      "4 -0.384330  -0.130726 -0.107844\n",
      "\n",
      "--- RFM Data with Cluster Labels ---\n",
      "   CustomerId  Recency  Frequency      Monetary  Cluster\n",
      "0           1      264          7   3055.866058        1\n",
      "1           2      345          2   1024.124932        1\n",
      "2           3       84         21   9982.865502        2\n",
      "3           4        4         26  13820.978961        2\n",
      "4           5       32         14   7128.400071        0\n",
      "\n",
      "Cluster distribution:\n",
      "Cluster\n",
      "2    233\n",
      "0    221\n",
      "1     46\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Cluster Analysis (Mean RFM Values) ---\n",
      "         AvgRecency  AvgFrequency   AvgMonetary  Count\n",
      "Cluster                                               \n",
      "1        327.934783      3.434783   1684.156236     46\n",
      "0         60.968326      9.529412   4707.201392    221\n",
      "2         29.128755     22.630901  11490.771126    233\n",
      "\n",
      "Identified High-Risk Cluster ID: 1\n",
      "\n",
      "--- RFM Data with 'is_high_risk' Label ---\n",
      "   CustomerId  Recency  Frequency      Monetary  Cluster  is_high_risk\n",
      "0           1      264          7   3055.866058        1             1\n",
      "1           2      345          2   1024.124932        1             1\n",
      "2           3       84         21   9982.865502        2             0\n",
      "3           4        4         26  13820.978961        2             0\n",
      "4           5       32         14   7128.400071        0             0\n",
      "\n",
      "High-risk customer count: 46\n",
      "\n",
      "--- Sample Main Processed Dataset (Before Merge) ---\n",
      "   CustomerId  Age        Income\n",
      "0           1   21  41488.010772\n",
      "1           2   59  98417.226025\n",
      "2           3   48  62316.142653\n",
      "3           4   23  60005.348855\n",
      "4           5   39  44060.951498\n",
      "\n",
      "Main dataset shape: (500, 3)\n",
      "\n",
      "--- Main Processed Dataset (After Merge with 'is_high_risk') ---\n",
      "   CustomerId  Age        Income  is_high_risk\n",
      "0           1   21  41488.010772             1\n",
      "1           2   59  98417.226025             1\n",
      "2           3   48  62316.142653             0\n",
      "3           4   23  60005.348855             0\n",
      "4           5   39  44060.951498             0\n",
      "\n",
      "Main dataset shape after merge: (500, 4)\n",
      "\n",
      "Missing 'is_high_risk' values: 0\n",
      "\n",
      "Distribution of 'is_high_risk':\n",
      "is_high_risk\n",
      "0    454\n",
      "1     46\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Generate Sample Transaction Data ---\n",
    "# In a real scenario, you would load your transaction data here.\n",
    "df_transactions = pd.read_csv('Final_preprocessed_data.csv')\n",
    "\n",
    "np.random.seed(42) # for reproducibility of synthetic data\n",
    "\n",
    "num_customers = 500\n",
    "start_date = datetime(2023, 1, 1)\n",
    "end_date = datetime(2024, 12, 31)\n",
    "\n",
    "data = []\n",
    "for customer_id in range(1, num_customers + 1):\n",
    "    # Simulate varying transaction frequencies and amounts\n",
    "    num_transactions = np.random.randint(1, 30) # Customers can have 1 to 30 transactions\n",
    "    for _ in range(num_transactions):\n",
    "        random_days = np.random.randint(0, (end_date - start_date).days)\n",
    "        transaction_date = start_date + timedelta(days=random_days)\n",
    "        amount = np.random.uniform(10, 1000) # Transaction amounts between 10 and 1000\n",
    "        data.append({'CustomerId': customer_id, 'TransactionDate': transaction_date, 'Amount': amount})\n",
    "\n",
    "df_transactions = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- Sample Transaction Data ---\")\n",
    "print(df_transactions.head())\n",
    "print(f\"\\nTotal transactions: {len(df_transactions)}\")\n",
    "print(f\"Unique customers: {df_transactions['CustomerId'].nunique()}\")\n",
    "\n",
    "# --- 2. Calculate RFM Metrics ---\n",
    "\n",
    "# Define a snapshot date: The day after the latest transaction in the dataset\n",
    "snapshot_date = df_transactions['TransactionDate'].max() + timedelta(days=1)\n",
    "print(f\"\\nSnapshot Date for Recency calculation: {snapshot_date}\")\n",
    "\n",
    "# Calculate RFM for each customer\n",
    "rfm_df = df_transactions.groupby('CustomerId').agg(\n",
    "    Recency=('TransactionDate', lambda date: (snapshot_date - date.max()).days),\n",
    "    Frequency=('TransactionDate', 'count'),\n",
    "    Monetary=('Amount', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"\\n--- Calculated RFM Metrics (Raw) ---\")\n",
    "print(rfm_df.head())\n",
    "print(f\"\\nRFM DataFrame shape: {rfm_df.shape}\")\n",
    "\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select RFM features for scaling\n",
    "rfm_features = rfm_df[['Recency', 'Frequency', 'Monetary']]\n",
    "\n",
    "# Scale the features\n",
    "scaled_rfm_features = scaler.fit_transform(rfm_features)\n",
    "scaled_rfm_df = pd.DataFrame(scaled_rfm_features, columns=rfm_features.columns, index=rfm_df.index)\n",
    "\n",
    "print(\"\\n--- Scaled RFM Features ---\")\n",
    "print(scaled_rfm_df.head())\n",
    "\n",
    "# --- 4. Cluster Customers using K-Means ---\n",
    "\n",
    "# Set random_state for reproducibility\n",
    "random_state = 42\n",
    "kmeans = KMeans(n_clusters=3, random_state=random_state, n_init=10) # n_init for robust centroid initialization\n",
    "\n",
    "# Fit K-Means to the scaled data\n",
    "kmeans.fit(scaled_rfm_df)\n",
    "\n",
    "# Add cluster labels to the RFM DataFrame\n",
    "rfm_df['Cluster'] = kmeans.labels_\n",
    "\n",
    "print(\"\\n--- RFM Data with Cluster Labels ---\")\n",
    "print(rfm_df.head())\n",
    "print(f\"\\nCluster distribution:\\n{rfm_df['Cluster'].value_counts()}\")\n",
    "\n",
    "cluster_analysis = rfm_df.groupby('Cluster').agg(\n",
    "    AvgRecency=('Recency', 'mean'),\n",
    "    AvgFrequency=('Frequency', 'mean'),\n",
    "    AvgMonetary=('Monetary', 'mean'),\n",
    "    Count=('CustomerId', 'count')\n",
    ").sort_values(by=['AvgRecency', 'AvgFrequency', 'AvgMonetary'], ascending=[False, True, True]) # Sort to find high-risk\n",
    "\n",
    "print(\"\\n--- Cluster Analysis (Mean RFM Values) ---\")\n",
    "print(cluster_analysis)\n",
    "high_risk_cluster_id = cluster_analysis.index[0]\n",
    "print(f\"\\nIdentified High-Risk Cluster ID: {high_risk_cluster_id}\")\n",
    "\n",
    "# Create the new binary target column 'is_high_risk'\n",
    "rfm_df['is_high_risk'] = rfm_df['Cluster'].apply(lambda x: 1 if x == high_risk_cluster_id else 0)\n",
    "\n",
    "print(\"\\n--- RFM Data with 'is_high_risk' Label ---\")\n",
    "print(rfm_df.head())\n",
    "print(f\"\\nHigh-risk customer count: {rfm_df['is_high_risk'].sum()}\")\n",
    "\n",
    "# --- 6. Integrate the Target Variable ---\n",
    "\n",
    "main_data = []\n",
    "for customer_id in range(1, num_customers + 1):\n",
    "    age = np.random.randint(20, 70)\n",
    "    income = np.random.uniform(30000, 100000)\n",
    "    main_data.append({'CustomerId': customer_id, 'Age': age, 'Income': income})\n",
    "\n",
    "df_main = pd.DataFrame(main_data)\n",
    "\n",
    "print(\"\\n--- Sample Main Processed Dataset (Before Merge) ---\")\n",
    "print(df_main.head())\n",
    "print(f\"\\nMain dataset shape: {df_main.shape}\")\n",
    "\n",
    "# Merge the 'is_high_risk' column back into the main processed dataset\n",
    "# We only need CustomerId and is_high_risk from rfm_df\n",
    "df_main = pd.merge(df_main, rfm_df[['CustomerId', 'is_high_risk']], on='CustomerId', how='left')\n",
    "\n",
    "print(\"\\n--- Main Processed Dataset (After Merge with 'is_high_risk') ---\")\n",
    "print(df_main.head())\n",
    "print(f\"\\nMain dataset shape after merge: {df_main.shape}\")\n",
    "\n",
    "# Verify that all customers from the main dataset have an 'is_high_risk' label\n",
    "print(f\"\\nMissing 'is_high_risk' values: {df_main['is_high_risk'].isnull().sum()}\")\n",
    "\n",
    "# Final check: distribution of the new target variable\n",
    "print(f\"\\nDistribution of 'is_high_risk':\\n{df_main['is_high_risk'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7caa5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main.to_csv('Final_processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2f0ef82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Income</th>\n",
       "      <th>is_high_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>41488.010772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>98417.226025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>62316.142653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>60005.348855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>44060.951498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>37</td>\n",
       "      <td>38601.290593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>63</td>\n",
       "      <td>36839.287258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>69</td>\n",
       "      <td>73301.787305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>48</td>\n",
       "      <td>79133.763135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>45</td>\n",
       "      <td>56389.526476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CustomerId  Age        Income  is_high_risk\n",
       "0             1   21  41488.010772             1\n",
       "1             2   59  98417.226025             1\n",
       "2             3   48  62316.142653             0\n",
       "3             4   23  60005.348855             0\n",
       "4             5   39  44060.951498             0\n",
       "..          ...  ...           ...           ...\n",
       "495         496   37  38601.290593             0\n",
       "496         497   63  36839.287258             0\n",
       "497         498   69  73301.787305             0\n",
       "498         499   48  79133.763135             0\n",
       "499         500   45  56389.526476             0\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60bfe435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6720a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/30 22:14:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data shape: (400, 3), Testing data shape: (100, 3)\n",
      "Distribution of target in training set:\n",
      "is_high_risk\n",
      "0    0.9175\n",
      "1    0.0825\n",
      "Name: proportion, dtype: float64\n",
      "Distribution of target in testing set:\n",
      "is_high_risk\n",
      "0    0.87\n",
      "1    0.13\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "--- Training Logistic Regression with GridSearchCV ---\n",
      "Best Logistic Regression parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "\n",
      "--- Logistic Regression (Tuned) Metrics ---\n",
      "Accuracy: 0.8700\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "ROC AUC: 0.5986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/30 22:14:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "2025/06/30 22:14:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Logistic Regression (Tuned)' logged to MLflow.\n",
      "\n",
      "--- Training Random Forest Classifier ---\n",
      "\n",
      "--- Random Forest Metrics ---\n",
      "Accuracy: 0.8600\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "ROC AUC: 0.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/06/30 22:14:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'CreditRiskHighRiskModel' already exists. Creating a new version of this model...\n",
      "2025/06/30 22:14:27 WARNING mlflow.tracking._model_registry.fluent: Run with id 28a585f9befa4cca96ec267de74595f1 has no artifacts at artifact path 'model', registering model based on models:/m-9b3adeb058f6410c9f6573fbf4f0a096 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'Random Forest' logged to MLflow.\n",
      "\n",
      "--- Best Model Identified ---\n",
      "Best Model: Logistic Regression (Tuned)\n",
      "Best ROC AUC: 0.5986\n",
      "Best Run ID: 28a585f9befa4cca96ec267de74595f1\n",
      "\n",
      "Registering 'Logistic Regression (Tuned)' (Run ID: 28a585f9befa4cca96ec267de74595f1) to MLflow Model Registry...\n",
      "Model registered as: CreditRiskHighRiskModel (Version: 2)\n",
      "\n",
      "--- Model Training, Tracking, and Registration Complete ---\n",
      "You can view the MLflow runs and registered models by starting the MLflow UI in your environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'CreditRiskHighRiskModel'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "X = df_main.drop(columns=['is_high_risk'])\n",
    "y = df_main['is_high_risk']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")\n",
    "print(f\"Distribution of target in training set:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Distribution of target in testing set:\\n{y_test.value_counts(normalize=True)}\")\n",
    "\n",
    "\n",
    "# Function to train, evaluate, and log model with MLflow\n",
    "def train_evaluate_log_model(model, model_name, X_train, y_train, X_test, y_test, params=None):\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        if params:\n",
    "            mlflow.log_params(params)\n",
    "        else:\n",
    "            mlflow.log_params(model.get_params())\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1] # Probability for the positive class\n",
    "\n",
    "        # Evaluate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "\n",
    "        print(f\"\\n--- {model_name} Metrics ---\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        print(f\"Model '{model_name}' logged to MLflow.\")\n",
    "        return roc_auc, run.info.run_id # Return ROC_AUC and run_id for best model selection\n",
    "\n",
    "\n",
    "# --- Choose and Train Models ---\n",
    "\n",
    "best_roc_auc = -1\n",
    "best_model_name = \"\"\n",
    "best_run_id = \"\"\n",
    "\n",
    "# Model 1: Logistic Regression (with Hyperparameter Tuning)\n",
    "print(\"\\n--- Training Logistic Regression with GridSearchCV ---\")\n",
    "log_reg = LogisticRegression(random_state=random_state, solver='liblinear')\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "grid_search_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "best_lr_model = grid_search_lr.best_estimator_\n",
    "print(f\"Best Logistic Regression parameters: {grid_search_lr.best_params_}\")\n",
    "current_roc_auc, current_run_id = train_evaluate_log_model(best_lr_model, \"Logistic Regression (Tuned)\", X_train, y_train, X_test, y_test, params=grid_search_lr.best_params_)\n",
    "\n",
    "if current_roc_auc > best_roc_auc:\n",
    "    best_roc_auc = current_roc_auc\n",
    "    best_model_name = \"Logistic Regression (Tuned)\"\n",
    "    best_run_id = current_run_id\n",
    "\n",
    "\n",
    "# Model 2: Random Forest Classifier\n",
    "print(\"\\n--- Training Random Forest Classifier ---\")\n",
    "rf_model = RandomForestClassifier(random_state=random_state, n_estimators=100)\n",
    "current_roc_auc, current_run_id = train_evaluate_log_model(rf_model, \"Random Forest\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "if current_roc_auc > best_roc_auc:\n",
    "    best_roc_auc = current_roc_auc\n",
    "    best_model_name = \"Random Forest\"\n",
    "    best_run_id = current_run_id\n",
    "\n",
    "print(f\"\\n--- Best Model Identified ---\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Best ROC AUC: {best_roc_auc:.4f}\")\n",
    "print(f\"Best Run ID: {best_run_id}\")\n",
    "\n",
    "# --- Register the Best Model in MLflow Model Registry ---\n",
    "if best_run_id:\n",
    "    print(f\"\\nRegistering '{best_model_name}' (Run ID: {best_run_id}) to MLflow Model Registry...\")\n",
    "    model_uri = f\"runs:/{best_run_id}/model\"\n",
    "    registered_model = mlflow.register_model(model_uri=model_uri, name=\"CreditRiskHighRiskModel\")\n",
    "    print(f\"Model registered as: {registered_model.name} (Version: {registered_model.version})\")\n",
    "else:\n",
    "    print(\"\\nNo best model identified or run ID available for registration.\")\n",
    "\n",
    "print(\"\\n--- Model Training, Tracking, and Registration Complete ---\")\n",
    "print(\"You can view the MLflow runs and registered models by starting the MLflow UI in your environment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
